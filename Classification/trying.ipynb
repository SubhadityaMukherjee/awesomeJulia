{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification of MNIST dataset \n",
    "## with the convolutional neural network know as LeNet5.\n",
    "## This script also combines various\n",
    "## packages from the Julia ecosystem  with Flux.\n",
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser, WeightDecay\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy\n",
    "using Statistics, Random\n",
    "using Parameters: @with_kw\n",
    "using Logging: with_logger, global_logger\n",
    "using TensorBoardLogger: TBLogger, tb_overwrite, set_step!, set_step_increment!\n",
    "import ProgressMeter\n",
    "import MLDatasets\n",
    "import DrWatson: savename, struct2dict\n",
    "import BSON\n",
    "using CUDAapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5 (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeNet5 \"constructor\". \n",
    "# The model can be adapted to any image size\n",
    "# and number of output classes.\n",
    "function LeNet5(; imgsize=(32,32,3), nclasses=10) \n",
    "    out_conv_size = (imgsize[1]÷4 - 3, imgsize[2]÷4 - 3, 16)\n",
    "    \n",
    "    return Chain(\n",
    "            x -> reshape(x, imgsize..., :),\n",
    "            Conv((5, 5), imgsize[end]=>6, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            Conv((5, 5), 6=>16, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            x -> reshape(x, :, size(x, 4)),\n",
    "            Dense(prod(out_conv_size), 120, relu), \n",
    "            Dense(120, 84, relu), \n",
    "            Dense(84, nclasses)\n",
    "          )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_data(args)\n",
    "    xtrain, ytrain = MLDatasets.CIFAR10.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.CIFAR10.testdata(Float32)\n",
    "    \n",
    "    xtrain = reshape(xtrain, 32, 32, 3, :)\n",
    "    xtest = reshape(xtest, 32, 32, 3, :)\n",
    "\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    train_loader = DataLoader(xtrain, ytrain, batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader = DataLoader(xtest, ytest,  batchsize=args.batchsize)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(ŷ, y) = logitcrossentropy(ŷ, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_loss_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_loss_accuracy(loader, model, device)\n",
    "    l = 0f0\n",
    "    acc = 0\n",
    "    ntot = 0\n",
    "    for (x, y) in loader\n",
    "        x, y = x |> device, y |> device\n",
    "        ŷ = model(x)\n",
    "        l += loss(ŷ, y) * size(x)[end]        \n",
    "        acc += sum(onecold(ŷ |> cpu) .== onecold(y |> cpu))\n",
    "        ntot += size(x)[end]\n",
    "    end\n",
    "    return (loss = l/ntot |> round4, acc = acc/ntot*100 |> round4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_params (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params(model) = sum(length, Flux.params(model)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round4 (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round4(x) = round(x, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arguments for the `train` function \n",
    "@with_kw mutable struct Args\n",
    "    η = 3e-4             # learning rate\n",
    "    λ = 0                # L2 regularizer param, implemented as weight decay\n",
    "    batchsize = 128      # batch size\n",
    "    epochs = 20          # number of epochs\n",
    "    seed = 0             # set seed > 0 for reproducibility\n",
    "    cuda = true          # if true use cuda (if available)\n",
    "    infotime = 1 \t     # report every `infotime` epochs\n",
    "    checktime = 5        # Save the model every `checktime` epochs. Set to 0 for no checkpoints.\n",
    "    tblogger = false      # log training with tensorboard\n",
    "    savepath = nothing    # results path. If nothing, construct a default path from Args. If existing, may overwrite\n",
    "#     args.imgsize, args.channels\n",
    "    datapath = joinpath(\"home/subhaditya/Datasets\", \"CIFAR10\") # data path: change to your data directory \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "    use_cuda = args.cuda && CUDAapi.has_cuda_gpu()\n",
    "    if use_cuda\n",
    "        device = gpu\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    ## DATA\n",
    "    train_loader, test_loader = get_data(args)\n",
    "    @info \"Dataset MNIST: $(train_loader.nobs) train and $(test_loader.nobs) test examples\"\n",
    "\n",
    "    ## MODEL AND OPTIMIZER\n",
    "    model = LeNet5() |> device\n",
    "    @info \"LeNet5 model: $(num_params(model)) trainable params\"    \n",
    "    \n",
    "    ps = Flux.params(model)  \n",
    "\n",
    "    opt = ADAM(args.η) \n",
    "    if args.λ > 0 \n",
    "        opt = Optimiser(opt, WeightDecay(args.λ))\n",
    "    end\n",
    "    \n",
    "    ## LOGGING UTILITIES\n",
    "    if args.savepath == nothing\n",
    "        experiment_folder = savename(\"lenet\", args, scientific=4,\n",
    "                    accesses=[:batchsize, :η, :seed, :λ]) # construct path from these fields\n",
    "        args.savepath = joinpath(\"runs\", experiment_folder)\n",
    "    end\n",
    "    if args.tblogger \n",
    "        tblogger = TBLogger(args.savepath, tb_overwrite)\n",
    "        set_step_increment!(tblogger, 0) # 0 auto increment since we manually set_step!\n",
    "        @info \"TensorBoard logging at \\\"$(args.savepath)\\\"\"\n",
    "    end\n",
    "    \n",
    "    function report(epoch)\n",
    "        train = eval_loss_accuracy(train_loader, model, device)\n",
    "        test = eval_loss_accuracy(test_loader, model, device)        \n",
    "        println(\"Epoch: $epoch   Train: $(train)   Test: $(test)\")\n",
    "        if args.tblogger\n",
    "            set_step!(tblogger, epoch)\n",
    "            with_logger(tblogger) do\n",
    "                @info \"train\" loss=train.loss  acc=train.acc\n",
    "                @info \"test\"  loss=test.loss   acc=test.acc\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    ## TRAINING\n",
    "    @info \"Start Training\"\n",
    "    report(0)\n",
    "    for epoch in 1:args.epochs\n",
    "        p = ProgressMeter.Progress(length(train_loader))\n",
    "\n",
    "        for (x, y) in train_loader\n",
    "            x, y = x |> device, y |> device\n",
    "            gs = Flux.gradient(ps) do\n",
    "                ŷ = model(x)\n",
    "                loss(ŷ, y)\n",
    "            end\n",
    "            Flux.Optimise.update!(opt, ps, gs)\n",
    "            ProgressMeter.next!(p)   # comment out for no progress bar\n",
    "        end\n",
    "        \n",
    "        epoch % args.infotime == 0 && report(epoch)\n",
    "        if args.checktime > 0 && epoch % args.checktime == 0\n",
    "            !ispath(args.savepath) && mkpath(args.savepath)\n",
    "            modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "            let model=cpu(model), args=struct2dict(args)\n",
    "                BSON.@save modelpath model epoch args\n",
    "            end\n",
    "            @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Train: (loss = 2.3049f0, acc = 10.208)   Test: (loss = 2.3046f0, acc = 10.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on GPU\n",
      "└ @ Main In[68]:7\n",
      "┌ Info: Dataset MNIST: 50000 train and 10000 test examples\n",
      "└ @ Main In[68]:15\n",
      "┌ Info: LeNet5 model: 62006 trainable params\n",
      "└ @ Main In[68]:19\n",
      "┌ Info: Start Training\n",
      "└ @ Main In[68]:54\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:21\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Train: (loss = 1.6796f0, acc = 39.538)   Test: (loss = 1.6818f0, acc = 39.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2   Train: (loss = 1.5387f0, acc = 44.794)   Test: (loss = 1.5482f0, acc = 44.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3   Train: (loss = 1.4981f0, acc = 45.956)   Test: (loss = 1.5106f0, acc = 45.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4   Train: (loss = 1.4075f0, acc = 49.752)   Test: (loss = 1.427f0, acc = 48.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5   Train: (loss = 1.3982f0, acc = 49.994)   Test: (loss = 1.4269f0, acc = 49.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[68]:76\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6   Train: (loss = 1.3562f0, acc = 51.458)   Test: (loss = 1.388f0, acc = 49.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7   Train: (loss = 1.307f0, acc = 53.52)   Test: (loss = 1.3495f0, acc = 51.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8   Train: (loss = 1.2958f0, acc = 53.958)   Test: (loss = 1.3424f0, acc = 51.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9   Train: (loss = 1.2539f0, acc = 55.598)   Test: (loss = 1.3079f0, acc = 52.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10   Train: (loss = 1.2162f0, acc = 56.948)   Test: (loss = 1.2723f0, acc = 54.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[68]:76\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11   Train: (loss = 1.1923f0, acc = 58.088)   Test: (loss = 1.2553f0, acc = 55.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12   Train: (loss = 1.1996f0, acc = 57.918)   Test: (loss = 1.2675f0, acc = 55.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13   Train: (loss = 1.1761f0, acc = 58.382)   Test: (loss = 1.2532f0, acc = 54.82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14   Train: (loss = 1.1501f0, acc = 59.516)   Test: (loss = 1.2285f0, acc = 56.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15   Train: (loss = 1.1365f0, acc = 59.862)   Test: (loss = 1.2267f0, acc = 56.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[68]:76\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16   Train: (loss = 1.1241f0, acc = 60.522)   Test: (loss = 1.2223f0, acc = 56.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17   Train: (loss = 1.1272f0, acc = 60.308)   Test: (loss = 1.2273f0, acc = 57.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18   Train: (loss = 1.0908f0, acc = 61.668)   Test: (loss = 1.1949f0, acc = 57.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19   Train: (loss = 1.0596f0, acc = 62.534)   Test: (loss = 1.1739f0, acc = 58.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20   Train: (loss = 1.0421f0, acc = 63.562)   Test: (loss = 1.1576f0, acc = 59.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[68]:76\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
